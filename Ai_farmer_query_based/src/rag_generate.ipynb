{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cdcb2e-34e4-4a47-adce-348b03d1516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index built and saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Paths\n",
    "DOCS_DIR = r\"C:\\Users\\Lenovo\\Ai_farmer_query_based\\data\\kb_docs\"       # folder containing your .txt files\n",
    "INDEX_PATH = \"data/faiss_index.idx\"\n",
    "META_PATH = \"data/faiss_meta.json\"\n",
    "DOCS_PATH = \"data/docs.json\"\n",
    "\n",
    "# Make sure the folder exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Load embedding model\n",
    "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Step 1: Load docs\n",
    "docs = []\n",
    "meta = []\n",
    "for fname in os.listdir(DOCS_DIR):\n",
    "    if fname.endswith(\".txt\"):\n",
    "        path = os.path.join(DOCS_DIR, fname)\n",
    "        with open(path, \"r\", encoding=\"utf8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        docs.append(text)\n",
    "        meta.append({\"source\": fname})\n",
    "\n",
    "# Step 2: Convert docs to embeddings\n",
    "embeddings = sbert.encode(docs, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "# Step 3: Build FAISS index\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)   # cosine similarity\n",
    "index.add(embeddings)\n",
    "\n",
    "# Step 4: Save index + metadata\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "\n",
    "with open(META_PATH, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(DOCS_PATH, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(docs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ FAISS index built and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d9249d-f23b-4273-bf26-0d5ed33e7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---- Load FAISS index & docs ----\n",
    "INDEX_PATH = \"data/faiss_index.idx\"\n",
    "META_PATH = \"data/faiss_meta.json\"\n",
    "DOCS_PATH = \"data/docs.json\"   # pre-saved list of chunks\n",
    "\n",
    "# ✅ Dhenu API client\n",
    "client = OpenAI(\n",
    "    api_key=\"dh-OJFkGcV-Iejz4PPjyGNy5w7DAJrmE7jlDQ-3dKwh7lo\",  # your Dhenu API key\n",
    "    base_url=\"https://api.dhenu.ai/v1\"  # Dhenu API base URL\n",
    ")\n",
    "\n",
    "# Embedding model\n",
    "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "with open(META_PATH, 'r', encoding='utf8') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "with open(DOCS_PATH, 'r', encoding='utf8') as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "\n",
    "# ---- Retrieval function ----\n",
    "def retrieve_docs(query, k=5):\n",
    "    q_emb = sbert.encode([query], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, k)\n",
    "    return [(docs[i], meta[i]) for i in I[0]]\n",
    "\n",
    "\n",
    "# ---- Retrieval with filtering ----\n",
    "def search(query, top_k=10):\n",
    "    q_emb = sbert.encode([query], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for i, score in zip(I[0], D[0]):\n",
    "        text, meta_info = docs[i], meta[i]\n",
    "        # keep only relevant passages by keyword filtering\n",
    "        if any(word in text.lower() for word in query.lower().split()):\n",
    "            results.append((text, meta_info))\n",
    "\n",
    "    # fallback: if filtering removes everything, keep top-3 anyway\n",
    "    if not results:\n",
    "        results = [(docs[i], meta[i]) for i in I[0][:3]]\n",
    "\n",
    "    return results[:5]  # limit to 5 best matches\n",
    "\n",
    "\n",
    "# ---- Prompt construction (farmer-friendly) ----\n",
    "def build_prompt(question, passages):\n",
    "    context = \"\\n\\n\".join([txt for txt, _ in passages])\n",
    "    prompt = f\"\"\"\n",
    "You are a practical agricultural advisor for Indian farmers. \n",
    "Base your answer ONLY on the following knowledge base. \n",
    "Ignore irrelevant or off-topic information. \n",
    "Do not mention files, sources, or documents.\n",
    "\n",
    "Knowledge Base:\n",
    "{context}\n",
    "\n",
    "Farmer's Question: {question}\n",
    "\n",
    "Answer:\n",
    "- Give step-by-step advice in simple language\n",
    "- Focus only on the farmer’s question\n",
    "- Keep it practical, natural, and directly useful\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# ---- Answer generation ----\n",
    "def generate_answer(question):\n",
    "    # ✅ Retrieve fewer docs\n",
    "    passages = search(question, top_k=3)  # pick top 3, not all\n",
    "    prompt = build_prompt(question, passages)\n",
    "\n",
    "    # Debug prompt length\n",
    "    print(\"Prompt length (chars):\", len(prompt))\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"dhenu2-in-8b-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.4,\n",
    "        max_tokens=100\n",
    "    )\n",
    "\n",
    "    # Safe extraction\n",
    "    answer = None\n",
    "    try:\n",
    "        if response and hasattr(response, \"choices\") and response.choices:\n",
    "            choice = response.choices[0]\n",
    "            if hasattr(choice, \"message\") and choice.message:\n",
    "                answer = choice.message.get(\"content\", \"\")\n",
    "            elif hasattr(choice, \"text\") and choice.text:\n",
    "                answer = choice.text\n",
    "            else:\n",
    "                answer = str(response)\n",
    "        else:\n",
    "            answer = str(response)\n",
    "    except Exception as e:\n",
    "        answer = f\"[Error extracting answer: {e}]\"\n",
    "\n",
    "    return {\"answer\": answer}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745e3cdd-4c67-4251-bc8f-54f828ae0dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length (chars): 108381\n",
      "Answer: ChatCompletion(id=None, choices=None, created=None, model=None, object='error', service_tier=None, system_fingerprint=None, usage=None, message=\"This model's maximum context length is 8192 tokens. However, you requested 43585 tokens (43485 in the messages, 100 in the completion). Please reduce the length of the messages or completion. None\", type='BadRequestError', param=None, code=400)\n"
     ]
    }
   ],
   "source": [
    "# ---- Quick test ----\n",
    "if __name__ == \"__main__\":\n",
    "    result = generate_answer(\"How to improve soil fertility naturally?\")\n",
    "    print(\"Answer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e993ab3-914d-4b4a-8501-ae9d9bdc1e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: [Error extracting answer: 'NoneType' object is not subscriptable]\n"
     ]
    }
   ],
   "source": [
    "# ---- Quick test ----\n",
    "if __name__ == \"__main__\":\n",
    "    result = generate_answer(\"now in this season it is good to crop wheat?\")\n",
    "    print(\"Answer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac670702-8ef1-448e-babc-a2025a78d474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
